{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00937bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a937f9",
   "metadata": {},
   "source": [
    "### Inspecting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7ebbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>r robert harley harley argote ch writes r dep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>at NUMBER NUMBER am NUMBER on NUMBER NUMBER NU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>in a message dated NUMBER NUMBER NUMBER NUMBE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>get access to the largest free adult site on t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>senior advocate of nigeria barr williams falan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>url URL date not supplied berkeley s impact th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>use perl daily headline mailer new perl monger...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>well it looks like sun are going ahead with th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>from chris garrigues cwg exmh deepeddy com da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>url URL date not supplied i ve put up a page c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>quoting brendan kehoe brendan zen org as a wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>original message from james rogers jamesr bes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>url URL date not supplied img URL wonderful ga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>hey i has just been given an old toshiba csNUM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>so i ve been letting the little exe of seti ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "349    r robert harley harley argote ch writes r dep...      0\n",
       "356   at NUMBER NUMBER am NUMBER on NUMBER NUMBER NU...      0\n",
       "714    in a message dated NUMBER NUMBER NUMBER NUMBE...      0\n",
       "2971  get access to the largest free adult site on t...      1\n",
       "2814  senior advocate of nigeria barr williams falan...      1\n",
       "2399  url URL date not supplied berkeley s impact th...      0\n",
       "1788  use perl daily headline mailer new perl monger...      0\n",
       "666   well it looks like sun are going ahead with th...      0\n",
       "13     from chris garrigues cwg exmh deepeddy com da...      0\n",
       "1886  url URL date not supplied i ve put up a page c...      0\n",
       "149   quoting brendan kehoe brendan zen org as a wor...      0\n",
       "695    original message from james rogers jamesr bes...      0\n",
       "2287  url URL date not supplied img URL wonderful ga...      0\n",
       "197   hey i has just been given an old toshiba csNUM...      0\n",
       "115   so i ve been letting the little exe of seti ho...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_or_not_spam.csv')\n",
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8f342c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2500\n",
       "1     500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d17b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email     True\n",
       "label    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25bd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fb6f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2500\n",
       "1     499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4042bd7",
   "metadata": {},
   "source": [
    "### creating a vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df69b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab= []\n",
    "for i in df.email:\n",
    "    vocab = vocab + i.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e8673c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679848a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stemming\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    vocab[i] = ps.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "312f93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it unique (no duplicates)\n",
    "\n",
    "vocab = list( dict.fromkeys(vocab) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f2cc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'date',\n",
       " 'wed',\n",
       " 'number',\n",
       " 'aug',\n",
       " 'from',\n",
       " 'chri',\n",
       " 'garrigu',\n",
       " 'cwg',\n",
       " 'numberfanumberd',\n",
       " 'deepeddi',\n",
       " 'com',\n",
       " 'messag',\n",
       " 'id',\n",
       " 'tmda',\n",
       " 'vircio',\n",
       " 'i',\n",
       " 'can',\n",
       " 't',\n",
       " 'reproduc',\n",
       " 'thi',\n",
       " 'error',\n",
       " 'for',\n",
       " 'me',\n",
       " 'it',\n",
       " 'is',\n",
       " 'veri',\n",
       " 'repeat',\n",
       " 'like',\n",
       " 'everi',\n",
       " 'time',\n",
       " 'without',\n",
       " 'fail',\n",
       " 'the',\n",
       " 'debug',\n",
       " 'log',\n",
       " 'of',\n",
       " 'pick',\n",
       " 'happen',\n",
       " 'pick_it',\n",
       " 'exec',\n",
       " 'inbox',\n",
       " 'list',\n",
       " 'lbrace',\n",
       " 'subject',\n",
       " 'ftp',\n",
       " 'rbrace',\n",
       " 'sequenc',\n",
       " 'mercuri',\n",
       " 'ftoc_pickmsg',\n",
       " 'hit',\n",
       " 'mark',\n",
       " 'tkerror',\n",
       " 'syntax',\n",
       " 'in',\n",
       " 'express',\n",
       " 'int',\n",
       " 'note',\n",
       " 'if',\n",
       " 'run',\n",
       " 'command',\n",
       " 'by',\n",
       " 'hand',\n",
       " 'delta',\n",
       " 'that',\n",
       " 's',\n",
       " 'where',\n",
       " 'come',\n",
       " 'obvious',\n",
       " 'version',\n",
       " 'nmh',\n",
       " 'm',\n",
       " 'use',\n",
       " 'compil',\n",
       " 'on',\n",
       " 'url',\n",
       " 'at',\n",
       " 'sun',\n",
       " 'mar',\n",
       " 'ict',\n",
       " 'and',\n",
       " 'relev',\n",
       " 'part',\n",
       " 'my',\n",
       " 'mh_profil',\n",
       " 'mhparam',\n",
       " 'seq',\n",
       " 'sel',\n",
       " 'sinc',\n",
       " 'work',\n",
       " 'actual',\n",
       " 'both',\n",
       " 'them',\n",
       " 'one',\n",
       " 'explicit',\n",
       " 'line',\n",
       " 'search',\n",
       " 'popup',\n",
       " 'do',\n",
       " 'get',\n",
       " 'creat',\n",
       " 'kre',\n",
       " 'ps',\n",
       " 'still',\n",
       " 'code',\n",
       " 'form',\n",
       " 'a',\n",
       " 'day',\n",
       " 'ago',\n",
       " 'haven',\n",
       " 'been',\n",
       " 'abl',\n",
       " 'to',\n",
       " 'reach',\n",
       " 'cv',\n",
       " 'repositori',\n",
       " 'today',\n",
       " 'local',\n",
       " 'rout',\n",
       " 'issu',\n",
       " 'think',\n",
       " '_______________________________________________',\n",
       " 'exmh',\n",
       " 'worker',\n",
       " 'mail',\n",
       " 'martin',\n",
       " 'post',\n",
       " 'tasso',\n",
       " 'papadopoulo',\n",
       " 'greek',\n",
       " 'sculptor',\n",
       " 'behind',\n",
       " 'plan',\n",
       " 'judg',\n",
       " 'limeston',\n",
       " 'mount',\n",
       " 'kerdylio',\n",
       " 'mile',\n",
       " 'east',\n",
       " 'salonika',\n",
       " 'not',\n",
       " 'far',\n",
       " 'atho',\n",
       " 'monast',\n",
       " 'commun',\n",
       " 'wa',\n",
       " 'ideal',\n",
       " 'patriot',\n",
       " 'sculptur',\n",
       " 'as',\n",
       " 'well',\n",
       " 'alexand',\n",
       " 'granit',\n",
       " 'featur',\n",
       " 'ft',\n",
       " 'high',\n",
       " 'wide',\n",
       " 'museum',\n",
       " 'restor',\n",
       " 'amphitheatr',\n",
       " 'car',\n",
       " 'park',\n",
       " 'admir',\n",
       " 'crowd',\n",
       " 'are',\n",
       " 'so',\n",
       " 'mountain',\n",
       " 'or',\n",
       " 'll',\n",
       " 'weather',\n",
       " 'pretti',\n",
       " 'fast',\n",
       " 'yahoo',\n",
       " 'group',\n",
       " 'sponsor',\n",
       " 'dvd',\n",
       " 'free',\n",
       " 'p',\n",
       " 'join',\n",
       " 'now',\n",
       " 'unsubscrib',\n",
       " 'send',\n",
       " 'an',\n",
       " 'email',\n",
       " 'forteana',\n",
       " 'your',\n",
       " 'man',\n",
       " 'threaten',\n",
       " 'explos',\n",
       " 'moscow',\n",
       " 'thursday',\n",
       " 'august',\n",
       " 'pm',\n",
       " 'ap',\n",
       " 'secur',\n",
       " 'offic',\n",
       " 'seiz',\n",
       " 'unidentifi',\n",
       " 'who',\n",
       " 'said',\n",
       " 'he',\n",
       " 'arm',\n",
       " 'with',\n",
       " 'blow',\n",
       " 'up',\n",
       " 'hi',\n",
       " 'truck',\n",
       " 'front',\n",
       " 'russia',\n",
       " 'feder',\n",
       " 'servic',\n",
       " 'headquart',\n",
       " 'ntv',\n",
       " 'televis',\n",
       " 'report',\n",
       " 'automat',\n",
       " 'rifl',\n",
       " 'carri',\n",
       " 'then',\n",
       " 'got',\n",
       " 'out',\n",
       " 'taken',\n",
       " 'into',\n",
       " 'custodi',\n",
       " 'no',\n",
       " 'other',\n",
       " 'detail',\n",
       " 'were',\n",
       " 'immedi',\n",
       " 'avail',\n",
       " 'had',\n",
       " 'demand',\n",
       " 'talk',\n",
       " 'govern',\n",
       " 'offici',\n",
       " 'interfax',\n",
       " 'itar',\n",
       " 'tass',\n",
       " 'news',\n",
       " 'agenc',\n",
       " 'ekho',\n",
       " 'moskvi',\n",
       " 'radio',\n",
       " 'want',\n",
       " 'russian',\n",
       " 'presid',\n",
       " 'vladimir',\n",
       " 'putin',\n",
       " 'polic',\n",
       " 'forc',\n",
       " 'rush',\n",
       " 'build',\n",
       " 'within',\n",
       " 'block',\n",
       " 'kremlin',\n",
       " 'red',\n",
       " 'squar',\n",
       " 'bolshoi',\n",
       " 'ballet',\n",
       " 'surround',\n",
       " 'claim',\n",
       " 'have',\n",
       " 'half',\n",
       " 'ton',\n",
       " 'negoti',\n",
       " 'continu',\n",
       " 'about',\n",
       " 'hour',\n",
       " 'outsid',\n",
       " 'cite',\n",
       " 'wit',\n",
       " 'later',\n",
       " 'drove',\n",
       " 'away',\n",
       " 'under',\n",
       " 'escort',\n",
       " 'street',\n",
       " 'near',\n",
       " 'olymp',\n",
       " 'penta',\n",
       " 'hotel',\n",
       " 'author',\n",
       " 'held',\n",
       " 'further',\n",
       " 'him',\n",
       " 'press',\n",
       " 'move',\n",
       " 'appear',\n",
       " 'be',\n",
       " 'attempt',\n",
       " 'more',\n",
       " 'locat',\n",
       " 'klez',\n",
       " 'viru',\n",
       " 'won',\n",
       " 'die',\n",
       " 'alreadi',\n",
       " 'most',\n",
       " 'prolif',\n",
       " 'ever',\n",
       " 'wreak',\n",
       " 'havoc',\n",
       " 'andrew',\n",
       " 'brandt',\n",
       " 'septemb',\n",
       " 'pc',\n",
       " 'world',\n",
       " 'magazin',\n",
       " 'worm',\n",
       " 'approach',\n",
       " 'seventh',\n",
       " 'month',\n",
       " 'wriggl',\n",
       " 'across',\n",
       " 'web',\n",
       " 'make',\n",
       " 'persist',\n",
       " 'virus',\n",
       " 'expert',\n",
       " 'warn',\n",
       " 'may',\n",
       " 'harbing',\n",
       " 'new',\n",
       " 'combin',\n",
       " 'pernici',\n",
       " 'go',\n",
       " 'antiviru',\n",
       " 'softwar',\n",
       " 'maker',\n",
       " 'symantec',\n",
       " 'mcafe',\n",
       " 'than',\n",
       " 'infect',\n",
       " 'daili',\n",
       " 'sign',\n",
       " 'letup',\n",
       " 'british',\n",
       " 'firm',\n",
       " 'messagelab',\n",
       " 'estim',\n",
       " 'e',\n",
       " 'hold',\n",
       " 'variat',\n",
       " 'say',\n",
       " 'ha',\n",
       " 'surpass',\n",
       " 'last',\n",
       " 'summer',\n",
       " 'sircam',\n",
       " 'some',\n",
       " 'newer',\n",
       " 'variant',\n",
       " 'aren',\n",
       " 'mere',\n",
       " 'nuisanc',\n",
       " 'they',\n",
       " 'corrupt',\n",
       " 'data',\n",
       " 'irregular',\n",
       " 'ad',\n",
       " 'cream',\n",
       " 'spaghetti',\n",
       " 'carbonara',\n",
       " 'which',\n",
       " 'same',\n",
       " 'effect',\n",
       " 'pasta',\n",
       " 'pizza',\n",
       " 'deep',\n",
       " 'pie',\n",
       " 'just',\n",
       " 'jump',\n",
       " 'here',\n",
       " 'favourit',\n",
       " 'ask',\n",
       " 'what',\n",
       " 'hell',\n",
       " 'you',\n",
       " 'suppos',\n",
       " 'instead',\n",
       " 've',\n",
       " 'never',\n",
       " 'seen',\n",
       " 'recip',\n",
       " 'hasn',\n",
       " 'person',\n",
       " 'low',\n",
       " 'fat',\n",
       " 'creme',\n",
       " 'fraich',\n",
       " 'becaus',\n",
       " 'quit',\n",
       " 'nice',\n",
       " 'but',\n",
       " 'onli',\n",
       " 'supposedli',\n",
       " 'authent',\n",
       " 'ident',\n",
       " 'mine',\n",
       " 'egg',\n",
       " 'lot',\n",
       " 'fresh',\n",
       " 'parmesan',\n",
       " 'except',\n",
       " 'stew',\n",
       " 'stewart',\n",
       " 'smith',\n",
       " 'scottish',\n",
       " 'microelectron',\n",
       " 'centr',\n",
       " 'univers',\n",
       " 'edinburgh',\n",
       " 'isn',\n",
       " 'basic',\n",
       " 'mixtur',\n",
       " 'beaten',\n",
       " 'bacon',\n",
       " 'pancetta',\n",
       " 'realli',\n",
       " 'mix',\n",
       " 'raw',\n",
       " 'cook',\n",
       " 'heat',\n",
       " 'understand',\n",
       " 'scotsman',\n",
       " 'playboy',\n",
       " 'bang',\n",
       " 'age',\n",
       " 'berlin',\n",
       " 'unusu',\n",
       " 'offer',\n",
       " 'lure',\n",
       " 'women',\n",
       " 'bed',\n",
       " 'promis',\n",
       " 'woman',\n",
       " 'sleep',\n",
       " 'inherit',\n",
       " 'rolf',\n",
       " 'eden',\n",
       " 'disco',\n",
       " 'owner',\n",
       " 'famou',\n",
       " 'countless',\n",
       " 'sex',\n",
       " 'partner',\n",
       " 'could',\n",
       " 'imagin',\n",
       " 'better',\n",
       " 'way',\n",
       " 'attract',\n",
       " 'young',\n",
       " 'prefer',\n",
       " 'put',\n",
       " 'all',\n",
       " 'will',\n",
       " 'testament',\n",
       " 'money',\n",
       " 'mr',\n",
       " 'told',\n",
       " 'bild',\n",
       " 'newspap',\n",
       " 'pass',\n",
       " 'beauti',\n",
       " 'moment',\n",
       " 'life',\n",
       " 'first',\n",
       " 'fun',\n",
       " 'wild',\n",
       " 'final',\n",
       " 'orgasm',\n",
       " 'end',\n",
       " 'heart',\n",
       " 'attack',\n",
       " 'gone',\n",
       " 'sell',\n",
       " 'nightclub',\n",
       " 'year',\n",
       " 'applic',\n",
       " 'should',\n",
       " 'sent',\n",
       " 'quickli',\n",
       " 'soon',\n",
       " 'adamson',\n",
       " 'wrote',\n",
       " 're',\n",
       " 'probabl',\n",
       " 'right',\n",
       " 'guess',\n",
       " 'tri',\n",
       " 'look',\n",
       " 'internet',\n",
       " 'found',\n",
       " 'possibl',\n",
       " 'scariest',\n",
       " 'peopl',\n",
       " 'us',\n",
       " 'congressman',\n",
       " 'worst',\n",
       " 'non',\n",
       " 'smile',\n",
       " 'apolog',\n",
       " 'ani',\n",
       " 'main',\n",
       " 'resid',\n",
       " 'vote',\n",
       " 'again',\n",
       " 'onc',\n",
       " 'pic',\n",
       " 'thu',\n",
       " 'meaning',\n",
       " 'sentenc',\n",
       " 'tracey',\n",
       " 'lawson',\n",
       " 'danger',\n",
       " 'inmat',\n",
       " 'prison',\n",
       " 'histori',\n",
       " 'describ',\n",
       " 'charl',\n",
       " 'bronson',\n",
       " 'chanc',\n",
       " 'serial',\n",
       " 'hostag',\n",
       " 'taker',\n",
       " 'movi',\n",
       " 'star',\n",
       " 'written',\n",
       " 'health',\n",
       " 'fit',\n",
       " 'guid',\n",
       " 'share',\n",
       " 'secret',\n",
       " 'legendari',\n",
       " 'muscl',\n",
       " 'power',\n",
       " 'solitari',\n",
       " 'titl',\n",
       " 'bear',\n",
       " 'fact',\n",
       " 'spent',\n",
       " 'confin',\n",
       " 'explain',\n",
       " 'how',\n",
       " 'turn',\n",
       " 'himself',\n",
       " 'lean',\n",
       " 'mean',\n",
       " 'machin',\n",
       " 'while',\n",
       " 'live',\n",
       " 'space',\n",
       " 'feet',\n",
       " 'eight',\n",
       " 'diet',\n",
       " 'scrub',\n",
       " 'grub',\n",
       " 'virtual',\n",
       " 'cost',\n",
       " 'book',\n",
       " 'aim',\n",
       " 'those',\n",
       " 'fabul',\n",
       " 'spend',\n",
       " 'fortun',\n",
       " 'gym',\n",
       " 'membership',\n",
       " 'protein',\n",
       " 'supplement',\n",
       " 'design',\n",
       " 'trainer',\n",
       " 'start',\n",
       " 'fierc',\n",
       " 'expens',\n",
       " 'myth',\n",
       " 'churn',\n",
       " 'exercis',\n",
       " 'industri',\n",
       " 'mag',\n",
       " 'laugh',\n",
       " 'wipe',\n",
       " 'ars',\n",
       " 'open',\n",
       " 'paragraph',\n",
       " 'pen',\n",
       " 'joke',\n",
       " 'big',\n",
       " 'con',\n",
       " 'call',\n",
       " 'crimin',\n",
       " 'help',\n",
       " 'feel',\n",
       " 'point',\n",
       " 'bar',\n",
       " 'publish',\n",
       " 'birdman',\n",
       " 'mind',\n",
       " 'draw',\n",
       " 'poem',\n",
       " 'discov',\n",
       " 'creativ',\n",
       " 'her',\n",
       " 'majesti',\n",
       " 'pleasur',\n",
       " 'jimmi',\n",
       " 'boyl',\n",
       " 'scot',\n",
       " 'novelist',\n",
       " 'artist',\n",
       " 'talent',\n",
       " 'when',\n",
       " 'barlinni',\n",
       " 'special',\n",
       " 'unit',\n",
       " 'their',\n",
       " 'violent',\n",
       " 'past',\n",
       " 'teach',\n",
       " 'emot',\n",
       " 'murder',\n",
       " 'bab',\n",
       " 'rooney',\n",
       " 'releas',\n",
       " 'becom',\n",
       " 'respect',\n",
       " 'novel',\n",
       " 'hero',\n",
       " 'underworld',\n",
       " 'autobiographi',\n",
       " 'sens',\n",
       " 'freedom',\n",
       " 'made',\n",
       " 'award',\n",
       " 'win',\n",
       " 'film',\n",
       " 'hugh',\n",
       " 'collin',\n",
       " 'jail',\n",
       " 'william',\n",
       " 'mooney',\n",
       " 'glasgow',\n",
       " 'stab',\n",
       " 'three',\n",
       " 'earn',\n",
       " 'extra',\n",
       " 'seven',\n",
       " 'after',\n",
       " 'transfer',\n",
       " 'attend',\n",
       " 'learn',\n",
       " 'sculpt',\n",
       " 'develop',\n",
       " 'interest',\n",
       " 'art',\n",
       " 'frank',\n",
       " 'account',\n",
       " 'cultur',\n",
       " 'receiv',\n",
       " 'critic',\n",
       " 'prais',\n",
       " 'lord',\n",
       " 'archer',\n",
       " 'doesn',\n",
       " 'seem',\n",
       " 'troubl',\n",
       " 'write',\n",
       " 'million',\n",
       " 'recent',\n",
       " 'deal',\n",
       " 'macmillan',\n",
       " 'worth',\n",
       " 'doubt',\n",
       " 'scribbl',\n",
       " 'we',\n",
       " 'speak',\n",
       " 'whi',\n",
       " 'men',\n",
       " 'destruct',\n",
       " 'toward',\n",
       " 'societi',\n",
       " 'stuck',\n",
       " 'insid',\n",
       " 'steve',\n",
       " 'richard',\n",
       " 'mani',\n",
       " 'figur',\n",
       " 'believ',\n",
       " 'root',\n",
       " 'phenomenon',\n",
       " 'pragmat',\n",
       " 'profound',\n",
       " 'sometim',\n",
       " 'known',\n",
       " 'stabl',\n",
       " 'environ',\n",
       " 'focu',\n",
       " 'skill',\n",
       " 'also',\n",
       " 'educ',\n",
       " 'earli',\n",
       " 'hard',\n",
       " 'anyon',\n",
       " 'explor',\n",
       " 'howev',\n",
       " 'reason',\n",
       " 'deeper',\n",
       " 'cold',\n",
       " 'light',\n",
       " 'examin',\n",
       " 'essenc',\n",
       " 'themselv',\n",
       " 'am',\n",
       " 'rememb',\n",
       " 'violenc',\n",
       " 'contribut',\n",
       " 'someth',\n",
       " 'good',\n",
       " 'born',\n",
       " 'michael',\n",
       " 'gordon',\n",
       " 'peterson',\n",
       " 'chang',\n",
       " 'name',\n",
       " 'hollywood',\n",
       " 'death',\n",
       " 'wish',\n",
       " 'mainli',\n",
       " 'thing',\n",
       " 'bad',\n",
       " 'origin',\n",
       " 'robberi',\n",
       " 'seri',\n",
       " 'term',\n",
       " 'over',\n",
       " 'result',\n",
       " 'convict',\n",
       " 'teacher',\n",
       " 'nearli',\n",
       " 'two',\n",
       " 'dure',\n",
       " 'sieg',\n",
       " 'stand',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'inch',\n",
       " 'tall',\n",
       " 'weigh',\n",
       " 'numberlb',\n",
       " 'renown',\n",
       " 'strength',\n",
       " 'bent',\n",
       " 'metal',\n",
       " 'cell',\n",
       " 'door',\n",
       " 'bare',\n",
       " 'doe',\n",
       " 'ye',\n",
       " 'four',\n",
       " 'second',\n",
       " 'push',\n",
       " 'our',\n",
       " 'current',\n",
       " 'obsess',\n",
       " 'might',\n",
       " 'see',\n",
       " 'face',\n",
       " 'sit',\n",
       " 'coffe',\n",
       " 'tabl',\n",
       " 'land',\n",
       " 'give',\n",
       " 'dream',\n",
       " 'bodi',\n",
       " 'guru',\n",
       " 'motiv',\n",
       " 'word',\n",
       " 'fist',\n",
       " 'crap',\n",
       " 'drink',\n",
       " 'pill',\n",
       " 'load',\n",
       " 'bollock',\n",
       " 'multi',\n",
       " 'pound',\n",
       " 'racket',\n",
       " 'refreshingli',\n",
       " 'honest',\n",
       " 'style',\n",
       " 'lazi',\n",
       " 'bastard',\n",
       " 'choic',\n",
       " 'sick',\n",
       " 'hear',\n",
       " 'read',\n",
       " 'excus',\n",
       " 'stuff',\n",
       " 'shit',\n",
       " 'logic',\n",
       " 'mantra',\n",
       " 'kick',\n",
       " 'er',\n",
       " 'backsid',\n",
       " 'need',\n",
       " 'mirag',\n",
       " 'bookstor',\n",
       " 'octob',\n",
       " 'research',\n",
       " 'via',\n",
       " 'sa',\n",
       " 'mirror',\n",
       " 'engin',\n",
       " 'script',\n",
       " 'exist',\n",
       " 'client',\n",
       " 'access',\n",
       " 'user_pref',\n",
       " 'option',\n",
       " 'base',\n",
       " 'cgi',\n",
       " 'interfac',\n",
       " 'numer',\n",
       " 'isp',\n",
       " 'provid',\n",
       " 'find',\n",
       " 'noth',\n",
       " 'configur',\n",
       " 'amavi',\n",
       " 'postfix',\n",
       " 'clamav',\n",
       " 'filter',\n",
       " 'procmail',\n",
       " 'spamassassin',\n",
       " 'spam',\n",
       " 'would',\n",
       " 'myself',\n",
       " 'appreci',\n",
       " 'suggest',\n",
       " 'osdn',\n",
       " 'tire',\n",
       " 'old',\n",
       " 'phone',\n",
       " 'hello',\n",
       " 'discuss',\n",
       " 'articl',\n",
       " 'thank',\n",
       " 'there',\n",
       " 'rule',\n",
       " 'accomplish',\n",
       " 'thoma',\n",
       " 'alva',\n",
       " 'edison',\n",
       " 'devel',\n",
       " 'great',\n",
       " 'alik',\n",
       " 'even',\n",
       " 'withput',\n",
       " 'eval',\n",
       " 'allow',\n",
       " 'respond',\n",
       " 'spammer',\n",
       " 'trick',\n",
       " 'theo',\n",
       " 'van',\n",
       " 'dinter',\n",
       " 'numberam',\n",
       " 'marc',\n",
       " 'perkel',\n",
       " 'though',\n",
       " 'idea',\n",
       " 'updat',\n",
       " 'user',\n",
       " 'cron',\n",
       " 'job',\n",
       " 'week',\n",
       " 'default',\n",
       " 'set',\n",
       " 'react',\n",
       " 'faster',\n",
       " 'few',\n",
       " 'don',\n",
       " 'came',\n",
       " 'requir',\n",
       " 'mon',\n",
       " 'numberpm',\n",
       " 'john',\n",
       " 'looney',\n",
       " 'mention',\n",
       " 'boot',\n",
       " 'cobalt',\n",
       " 'dev',\n",
       " 'hdanumb',\n",
       " 'kernel',\n",
       " 'mdnumber',\n",
       " 'solv',\n",
       " 'box',\n",
       " 'wasn',\n",
       " 'barf',\n",
       " 'init',\n",
       " 'popul',\n",
       " 'tar',\n",
       " 'crosslink',\n",
       " 'file',\n",
       " 'instanc',\n",
       " 'link',\n",
       " 'hda',\n",
       " 'did',\n",
       " 'friend',\n",
       " 'present',\n",
       " 'spot',\n",
       " 'queri',\n",
       " 'notic',\n",
       " 'didn',\n",
       " 'rootf',\n",
       " 'duplic',\n",
       " 'filesystem',\n",
       " 'dump',\n",
       " 'fine',\n",
       " 'tell',\n",
       " 'lilo',\n",
       " 'everyth',\n",
       " 'woohoo',\n",
       " 'kate',\n",
       " 'irish',\n",
       " 'linux',\n",
       " 'ilug',\n",
       " 'un',\n",
       " 'subscript',\n",
       " 'inform',\n",
       " 'maintain',\n",
       " 'listmast',\n",
       " 'ouch',\n",
       " 'robert',\n",
       " 'elz',\n",
       " 'munnari',\n",
       " 'oz',\n",
       " 'au',\n",
       " 'lengthen',\n",
       " 'column',\n",
       " 'display',\n",
       " 'detach',\n",
       " 'd',\n",
       " 'folder',\n",
       " 'window',\n",
       " 'take',\n",
       " 'full',\n",
       " 'screen',\n",
       " 'top',\n",
       " 'bottom',\n",
       " 'less',\n",
       " 'width',\n",
       " 'etc',\n",
       " 'thought',\n",
       " 'order',\n",
       " 'approxim',\n",
       " 'add',\n",
       " 'pack',\n",
       " 'side',\n",
       " 'left',\n",
       " 'each',\n",
       " 'differ',\n",
       " 'funni',\n",
       " 'done',\n",
       " 'leav',\n",
       " 'cosmet',\n",
       " 'document',\n",
       " 'todo',\n",
       " 'vacat',\n",
       " 'function',\n",
       " 'much',\n",
       " 'own',\n",
       " 'bug',\n",
       " 'fix',\n",
       " 'befor',\n",
       " 'hope',\n",
       " 'afterward',\n",
       " 'congress',\n",
       " 'suit',\n",
       " 'austin',\n",
       " 'tx',\n",
       " 'war',\n",
       " 'iii',\n",
       " 'wrong',\n",
       " 'doer',\n",
       " 'vs',\n",
       " 'evil',\n",
       " 'hurt',\n",
       " 'democraci',\n",
       " 'owen',\n",
       " 'level',\n",
       " 'polit',\n",
       " 'play',\n",
       " 'field',\n",
       " 'mike',\n",
       " 'mccurri',\n",
       " 'larri',\n",
       " 'purpuro',\n",
       " 'countri',\n",
       " 'experi',\n",
       " 'recur',\n",
       " 'american',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b253adf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25875"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774e505",
   "metadata": {},
   "source": [
    "### Converting email to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf38afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_vector(email):\n",
    "    vector = np.zeros(len(vocab))\n",
    "    for word in email.split(\" \"):\n",
    "        stemmed_word = ps.stem(word)\n",
    "        if stemmed_word in vocab:\n",
    "            vector[vocab.index(stemmed_word)] += 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec9ca36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = email_to_vector(df.email[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1d5d0",
   "metadata": {},
   "source": [
    "### initializing training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe19322",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbc8bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all eamils into vectors\n",
    "X = np.array([email_to_vector(email) for email in df.email])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0510adef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 25875)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f52f3bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "148c6d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [2., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a4970",
   "metadata": {},
   "source": [
    "### classifier (most fun part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac922f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b0328a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MrSwi\\anaconda3\\envs\\projects\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MrSwi\\anaconda3\\envs\\projects\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MrSwi\\anaconda3\\envs\\projects\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.972     , 0.974     , 0.98798799])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model,X,y,cv=3,scoring='accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
